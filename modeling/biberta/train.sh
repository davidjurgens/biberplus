accelerate launch --num_processes=7 main.py --wandb --run_name roberta-base2-64 --style_dimensions 64 --out_dir '/shared/3/projects/hiatus/models/style-mlm/' --train_data '/shared/3/projects/hiatus/tagged_data/mlm_finetuning/train2.jsonl' --dev_data '/shared/3/projects/hiatus/tagged_data/mlm_finetuning/dev2.jsonl' --tokenizer='roberta-base' --num_warmup_steps=200 --grad_acc 100 --gradient_checkpointing true --epochs 10 --pretrained_model 'roberta-base' --evaluate --batch_size 64 --eval_batch_size 64 --saving_step 40